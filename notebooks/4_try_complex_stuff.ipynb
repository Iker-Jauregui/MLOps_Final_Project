{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e559f3b-9e15-42c5-87f9-4006bf4f5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad763cd-5876-4314-8888-81ada82e0965",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a671541-b4f8-4876-990f-e2a8242a8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"df_train_ensemble_2022-07-01_2025-10-01_V.1.0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b67b520-0729-432c-bdca-9ed000f64e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reporting_month</th>\n",
       "      <th>ISRC</th>\n",
       "      <th>spotify</th>\n",
       "      <th>release_type</th>\n",
       "      <th>continent</th>\n",
       "      <th>zone</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>mechanical_fee</th>\n",
       "      <th>share_rate</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>CA-5KR-00-21353</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>GX-5MX-22-31727</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>GX-5MX-22-31730</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>CA-5KR-21-13899</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Bosnia and herzegovi</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>CA-5KR-21-77573</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reporting_month             ISRC spotify   release_type continent  \\\n",
       "0      2022/09/01  CA-5KR-00-21353   Other  Music Release    Europe   \n",
       "1      2022/09/01  GX-5MX-22-31727   Other  Music Release    Europe   \n",
       "2      2022/09/01  GX-5MX-22-31730   Other  Music Release     LATAM   \n",
       "3      2022/09/01  CA-5KR-21-13899   Other  Music Release    Europe   \n",
       "4      2022/09/01  CA-5KR-21-77573   Other  Music Release      Asia   \n",
       "\n",
       "                   zone  quantity  unit_price  mechanical_fee  share_rate  \\\n",
       "0                 Italy         1    0.000007             0.0       0.765   \n",
       "1                Turkey         1    0.000007             0.0       0.765   \n",
       "2               Uruguay         1    0.000010             0.0       0.765   \n",
       "3  Bosnia and herzegovi         5    0.000002             0.0       0.765   \n",
       "4                Jordan         1    0.000014             0.0       0.765   \n",
       "\n",
       "    revenue  \n",
       "0  0.000005  \n",
       "1  0.000005  \n",
       "2  0.000008  \n",
       "3  0.000008  \n",
       "4  0.000011  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49969dd8-1684-4abf-8a1b-7c16878dac9e",
   "metadata": {},
   "source": [
    "# Delete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec68a8fc-fc1e-4469-abc6-d8e8859eb2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reporting_month</th>\n",
       "      <th>ISRC</th>\n",
       "      <th>spotify</th>\n",
       "      <th>release_type</th>\n",
       "      <th>continent</th>\n",
       "      <th>quantity</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>CA-5KR-00-21353</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>GX-5MX-22-31727</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>GX-5MX-22-31730</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>CA-5KR-21-13899</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01</td>\n",
       "      <td>CA-5KR-21-77573</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896238</th>\n",
       "      <td>2025/10/01</td>\n",
       "      <td>DG-A0M-23-83965</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>98444</td>\n",
       "      <td>295.409068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896239</th>\n",
       "      <td>2025/10/01</td>\n",
       "      <td>FR-X20-25-23762</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>North America</td>\n",
       "      <td>121046</td>\n",
       "      <td>348.794584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896240</th>\n",
       "      <td>2025/10/01</td>\n",
       "      <td>FR-X20-25-89898</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>119656</td>\n",
       "      <td>352.407716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896241</th>\n",
       "      <td>2025/10/01</td>\n",
       "      <td>FR-X20-25-89898</td>\n",
       "      <td>Other</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>North America</td>\n",
       "      <td>113698</td>\n",
       "      <td>358.880249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896242</th>\n",
       "      <td>2025/10/01</td>\n",
       "      <td>FR-X20-25-23762</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>Music Release</td>\n",
       "      <td>Europe</td>\n",
       "      <td>192876</td>\n",
       "      <td>585.801136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896243 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reporting_month             ISRC  spotify   release_type  \\\n",
       "0           2022/09/01  CA-5KR-00-21353    Other  Music Release   \n",
       "1           2022/09/01  GX-5MX-22-31727    Other  Music Release   \n",
       "2           2022/09/01  GX-5MX-22-31730    Other  Music Release   \n",
       "3           2022/09/01  CA-5KR-21-13899    Other  Music Release   \n",
       "4           2022/09/01  CA-5KR-21-77573    Other  Music Release   \n",
       "...                ...              ...      ...            ...   \n",
       "896238      2025/10/01  DG-A0M-23-83965  Spotify  Music Release   \n",
       "896239      2025/10/01  FR-X20-25-23762  Spotify  Music Release   \n",
       "896240      2025/10/01  FR-X20-25-89898    Other  Music Release   \n",
       "896241      2025/10/01  FR-X20-25-89898    Other  Music Release   \n",
       "896242      2025/10/01  FR-X20-25-23762  Spotify  Music Release   \n",
       "\n",
       "            continent  quantity     revenue  \n",
       "0              Europe         1    0.000005  \n",
       "1              Europe         1    0.000005  \n",
       "2               LATAM         1    0.000008  \n",
       "3              Europe         5    0.000008  \n",
       "4                Asia         1    0.000011  \n",
       "...               ...       ...         ...  \n",
       "896238         Europe     98444  295.409068  \n",
       "896239  North America    121046  348.794584  \n",
       "896240         Europe    119656  352.407716  \n",
       "896241  North America    113698  358.880249  \n",
       "896242         Europe    192876  585.801136  \n",
       "\n",
       "[896243 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['zone', 'unit_price', 'mechanical_fee', 'share_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c6014-5dd8-4a8c-b252-603b55093497",
   "metadata": {},
   "source": [
    "# Claude ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f4bdda-3eac-468c-a931-31ec44ead27d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Modelos\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Crea features temporales y agregadas\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Asegurar que reporting_month es datetime\n",
    "    df['reporting_month'] = pd.to_datetime(df['reporting_month'])\n",
    "    \n",
    "    # Features temporales básicas\n",
    "    df['year'] = df['reporting_month'].dt.year\n",
    "    df['month'] = df['reporting_month'].dt.month\n",
    "    df['quarter'] = df['reporting_month'].dt.quarter\n",
    "    df['day_of_year'] = df['reporting_month'].dt.dayofyear\n",
    "    \n",
    "    # Encoding cíclico para mes (captura estacionalidad)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # Timestamp normalizado (días desde inicio)\n",
    "    min_date = df['reporting_month'].min()\n",
    "    df['days_since_start'] = (df['reporting_month'] - min_date).dt.days\n",
    "    df['days_since_start_norm'] = df['days_since_start'] / df['days_since_start'].max()\n",
    "    \n",
    "    # Features agregadas por ISRC\n",
    "    df['isrc_avg_revenue'] = df.groupby('ISRC')['revenue'].transform('mean')\n",
    "    df['isrc_std_revenue'] = df.groupby('ISRC')['revenue'].transform('std').fillna(0)\n",
    "    df['isrc_total_quantity'] = df.groupby('ISRC')['quantity'].transform('sum')\n",
    "    df['isrc_appearance_count'] = df.groupby('ISRC')['ISRC'].transform('count')\n",
    "    \n",
    "    # Features agregadas por continente\n",
    "    df['continent_avg_revenue'] = df.groupby('continent')['revenue'].transform('mean')\n",
    "    df['continent_avg_quantity'] = df.groupby('continent')['quantity'].transform('mean')\n",
    "    \n",
    "    # Features de combinaciones\n",
    "    df['quantity_per_appearance'] = df['quantity'] / (df['isrc_appearance_count'] + 1)\n",
    "    \n",
    "    # Revenue por unidad (puede ser útil)\n",
    "    df['revenue_per_quantity'] = df['revenue'] / (df['quantity'] + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SPLIT TEMPORAL\n",
    "# ============================================================================\n",
    "\n",
    "def temporal_split(df, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Split temporal: train (70%), validation (15%), test (15%)\n",
    "    \"\"\"\n",
    "    df = df.sort_values('reporting_month').reset_index(drop=True)\n",
    "    \n",
    "    n = len(df)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    \n",
    "    train = df.iloc[:train_end]\n",
    "    val = df.iloc[train_end:val_end]\n",
    "    test = df.iloc[val_end:]\n",
    "    \n",
    "    print(f\"Train: {len(train)} rows ({train['reporting_month'].min()} to {train['reporting_month'].max()})\")\n",
    "    print(f\"Val:   {len(val)} rows ({val['reporting_month'].min()} to {val['reporting_month'].max()})\")\n",
    "    print(f\"Test:  {len(test)} rows ({test['reporting_month'].min()} to {test['reporting_month'].max()})\")\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "# ============================================================================\n",
    "# 3. ENCODING DE CATEGORÍAS\n",
    "# ============================================================================\n",
    "\n",
    "def encode_features(train, val, test, categorical_cols):\n",
    "    \"\"\"\n",
    "    Label encoding de variables categóricas\n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        # Fit solo en train\n",
    "        le.fit(train[col].astype(str))\n",
    "        \n",
    "        # Transform en todos los sets\n",
    "        train[f'{col}_encoded'] = le.transform(train[col].astype(str))\n",
    "        \n",
    "        # Para val y test, manejar categorías no vistas\n",
    "        val[f'{col}_encoded'] = val[col].astype(str).map(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "        )\n",
    "        test[f'{col}_encoded'] = test[col].astype(str).map(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "        )\n",
    "        \n",
    "        encoders[col] = le\n",
    "    \n",
    "    return train, val, test, encoders\n",
    "\n",
    "# ============================================================================\n",
    "# 4. MODELO 1: LIGHTGBM\n",
    "# ============================================================================\n",
    "\n",
    "def train_lightgbm(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Entrena LightGBM - muy eficiente para datos grandes\n",
    "    \"\"\"\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=0)\n",
    "        ] if hasattr(tf.keras.callbacks, 'EarlyStopping') else None\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# 5. MODELO 2: XGBOOST\n",
    "# ============================================================================\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Entrena XGBoost\n",
    "    \"\"\"\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# 6. MODELO 3: NEURAL NETWORK (PyTorch Lightning)\n",
    "# ============================================================================\n",
    "\n",
    "class MusicRevenueDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para PyTorch\n",
    "    \"\"\"\n",
    "    def __init__(self, X_numeric, X_categorical, y):\n",
    "        self.X_numeric = torch.FloatTensor(X_numeric)\n",
    "        self.X_categorical = [torch.LongTensor(cat) for cat in X_categorical]\n",
    "        self.y = torch.FloatTensor(y.values).reshape(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'numeric': self.X_numeric[idx],\n",
    "            'categorical': [cat[idx] for cat in self.X_categorical],\n",
    "            'target': self.y[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "class MusicRevenueModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Red neuronal con embeddings para variables categóricas\n",
    "    \"\"\"\n",
    "    def __init__(self, numeric_dim, categorical_dims, embedding_dim=50, \n",
    "                 hidden_dims=[256, 128, 64], dropout=0.3, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        # Embeddings para variables categóricas\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(vocab_size + 1, min(embedding_dim, (vocab_size + 1) // 2))\n",
    "            for vocab_size in categorical_dims\n",
    "        ])\n",
    "        \n",
    "        # Calcular dimensión total después de embeddings\n",
    "        embedding_total_dim = sum([min(embedding_dim, (vs + 1) // 2) for vs in categorical_dims])\n",
    "        total_input_dim = numeric_dim + embedding_total_dim\n",
    "        \n",
    "        # Capas densas\n",
    "        layers = []\n",
    "        prev_dim = total_input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.Dropout(dropout if i == 0 else dropout * 0.7))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_dim, 1)\n",
    "        \n",
    "        # Métricas\n",
    "        self.train_mae = []\n",
    "        self.val_mae = []\n",
    "    \n",
    "    def forward(self, numeric, categorical):\n",
    "        # Embeddings\n",
    "        embedded = [emb(cat.squeeze()) for emb, cat in zip(self.embeddings, categorical)]\n",
    "        \n",
    "        # Concatenar numeric + embeddings\n",
    "        x = torch.cat([numeric] + embedded, dim=1)\n",
    "        \n",
    "        # Forward pass\n",
    "        x = self.fc_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        numeric = batch['numeric']\n",
    "        categorical = batch['categorical']\n",
    "        target = batch['target']\n",
    "        \n",
    "        pred = self(numeric, categorical)\n",
    "        loss = nn.functional.mse_loss(pred, target)\n",
    "        mae = nn.functional.l1_loss(pred, target)\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_mae', mae, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        numeric = batch['numeric']\n",
    "        categorical = batch['categorical']\n",
    "        target = batch['target']\n",
    "        \n",
    "        pred = self(numeric, categorical)\n",
    "        loss = nn.functional.mse_loss(pred, target)\n",
    "        mae = nn.functional.l1_loss(pred, target)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_mae', mae, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def train_neural_network(X_train, y_train, X_val, y_val, categorical_cols=None):\n",
    "    \"\"\"\n",
    "    Entrena red neuronal con PyTorch Lightning\n",
    "    \"\"\"\n",
    "    # Escalar features numéricas\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Separar categóricas y numéricas\n",
    "    if categorical_cols:\n",
    "        numeric_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "        X_train_num = scaler.fit_transform(X_train[numeric_cols])\n",
    "        X_val_num = scaler.transform(X_val[numeric_cols])\n",
    "        \n",
    "        # Preparar categóricas\n",
    "        categorical_dims = [int(X_train[col].max()) + 1 for col in categorical_cols]\n",
    "        X_train_cat = [X_train[col].values for col in categorical_cols]\n",
    "        X_val_cat = [X_val[col].values for col in categorical_cols]\n",
    "    else:\n",
    "        X_train_num = scaler.fit_transform(X_train)\n",
    "        X_val_num = scaler.transform(X_val)\n",
    "        categorical_dims = []\n",
    "        X_train_cat = []\n",
    "        X_val_cat = []\n",
    "    \n",
    "    # Crear datasets\n",
    "    train_dataset = MusicRevenueDataset(X_train_num, X_train_cat, y_train)\n",
    "    val_dataset = MusicRevenueDataset(X_val_num, X_val_cat, y_val)\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Crear modelo\n",
    "    model = MusicRevenueModel(\n",
    "        numeric_dim=X_train_num.shape[1],\n",
    "        categorical_dims=categorical_dims,\n",
    "        embedding_dim=50,\n",
    "        hidden_dims=[256, 128, 64],\n",
    "        dropout=0.3,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_top_k=1,\n",
    "        filename='best-model-{epoch:02d}-{val_loss:.6f}'\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        accelerator='auto',  # Usa GPU si está disponible\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=50\n",
    "    )\n",
    "    \n",
    "    # Entrenar\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # Cargar mejor modelo\n",
    "    best_model = MusicRevenueModel.load_from_checkpoint(\n",
    "        checkpoint.best_model_path,\n",
    "        numeric_dim=X_train_num.shape[1],\n",
    "        categorical_dims=categorical_dims\n",
    "    )\n",
    "    \n",
    "    return best_model, scaler, trainer\n",
    "\n",
    "\n",
    "def predict_with_nn(model, X_test, scaler, categorical_cols):\n",
    "    \"\"\"\n",
    "    Realiza predicciones con el modelo de PyTorch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Preparar datos\n",
    "    numeric_cols = [col for col in X_test.columns if col not in categorical_cols]\n",
    "    X_test_num = scaler.transform(X_test[numeric_cols])\n",
    "    X_test_cat = [X_test[col].values for col in categorical_cols]\n",
    "    \n",
    "    # Crear dataset y dataloader\n",
    "    y_dummy = pd.Series([0] * len(X_test))  # Dummy target\n",
    "    test_dataset = MusicRevenueDataset(X_test_num, X_test_cat, y_dummy)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "    \n",
    "    # Predicciones\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            numeric = batch['numeric']\n",
    "            categorical = batch['categorical']\n",
    "            pred = model(numeric, categorical)\n",
    "            predictions.append(pred.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(predictions).flatten()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. EVALUACIÓN\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Evalúa modelo y muestra métricas\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{model_name} - Resultados:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"MAE:  ${mae:.6f}\")\n",
    "    print(f\"RMSE: ${rmse:.6f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}\n",
    "\n",
    "# ============================================================================\n",
    "# 8. PIPELINE COMPLETO\n",
    "# ============================================================================\n",
    "\n",
    "def run_complete_pipeline(df):\n",
    "    \"\"\"\n",
    "    Pipeline completo de entrenamiento y evaluación\n",
    "    \"\"\"\n",
    "    print(\"Iniciando pipeline...\")\n",
    "    print(f\"Dataset: {len(df)} filas\\n\")\n",
    "    \n",
    "    # 1. Feature Engineering\n",
    "    print(\"1. Creando features...\")\n",
    "    df = create_features(df)\n",
    "    \n",
    "    # 2. Split temporal\n",
    "    print(\"\\n2. Split temporal...\")\n",
    "    train, val, test = temporal_split(df)\n",
    "    \n",
    "    # 3. Encoding\n",
    "    print(\"\\n3. Encoding de variables categóricas...\")\n",
    "    categorical_cols = ['ISRC', 'spotify', 'release_type', 'continent']\n",
    "    train, val, test, encoders = encode_features(train, val, test, categorical_cols)\n",
    "    \n",
    "    # 4. Preparar features\n",
    "    feature_cols = [\n",
    "        'year', 'month', 'quarter', 'month_sin', 'month_cos',\n",
    "        'days_since_start_norm', 'quantity',\n",
    "        'isrc_avg_revenue', 'isrc_std_revenue', 'isrc_total_quantity',\n",
    "        'isrc_appearance_count', 'continent_avg_revenue',\n",
    "        'continent_avg_quantity', 'quantity_per_appearance',\n",
    "        'ISRC_encoded', 'spotify_encoded', 'release_type_encoded', 'continent_encoded'\n",
    "    ]\n",
    "    \n",
    "    X_train = train[feature_cols]\n",
    "    y_train = train['revenue']\n",
    "    X_val = val[feature_cols]\n",
    "    y_val = val['revenue']\n",
    "    X_test = test[feature_cols]\n",
    "    y_test = test['revenue']\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 5. Entrenar LightGBM\n",
    "    print(\"\\n4. Entrenando LightGBM...\")\n",
    "    lgb_model = train_lightgbm(X_train, y_train, X_val, y_val)\n",
    "    lgb_pred = lgb_model.predict(X_test)\n",
    "    results['LightGBM'] = evaluate_model(y_test, lgb_pred, \"LightGBM\")\n",
    "    \n",
    "    # 6. Entrenar XGBoost\n",
    "    print(\"\\n5. Entrenando XGBoost...\")\n",
    "    xgb_model = train_xgboost(X_train, y_train, X_val, y_val)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    results['XGBoost'] = evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
    "    \n",
    "    # 7. Entrenar Neural Network\n",
    "    print(\"\\n6. Entrenando Neural Network...\")\n",
    "    categorical_encoded = ['ISRC_encoded', 'spotify_encoded', 'release_type_encoded', 'continent_encoded']\n",
    "    nn_model, scaler, history = train_neural_network(\n",
    "        X_train, y_train, X_val, y_val, \n",
    "        categorical_cols=categorical_encoded\n",
    "    )\n",
    "    \n",
    "    # Preparar datos para predicción NN\n",
    "    numeric_cols = [col for col in feature_cols if col not in categorical_encoded]\n",
    "    X_test_num = scaler.transform(X_test[numeric_cols])\n",
    "    X_test_cat = [X_test[col].values.reshape(-1, 1) for col in categorical_encoded]\n",
    "    nn_pred = nn_model.predict([X_test_num] + X_test_cat, verbose=0).flatten()\n",
    "    results['Neural Network'] = evaluate_model(y_test, nn_pred, \"Neural Network\")\n",
    "    \n",
    "    # 8. Comparación final\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"COMPARACIÓN FINAL\")\n",
    "    print(\"=\"*50)\n",
    "    comparison_df = pd.DataFrame(results).T\n",
    "    print(comparison_df.to_string())\n",
    "    \n",
    "    # Feature importance de LightGBM\n",
    "    print(\"\\n\\nTop 10 Features más importantes (LightGBM):\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': lgb_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(10)\n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'models': {'lgb': lgb_model, 'xgb': xgb_model, 'nn': nn_model},\n",
    "        'results': results,\n",
    "        'encoders': encoders,\n",
    "        'scaler': scaler,\n",
    "        'feature_cols': feature_cols\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# EJEMPLO DE USO\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9ebb4-a871-47fd-91df-fc581caee431",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Cargar tus datos\n",
    "    # df = pd.read_csv('tu_archivo.csv')\n",
    "    \n",
    "    # Ejecutar pipeline completo\n",
    "    # pipeline_output = run_complete_pipeline(df)\n",
    "    \n",
    "    print(\"Pipeline listo para usar.\")\n",
    "    print(\"\\nPara ejecutar:\")\n",
    "    print(\"  pipeline_output = run_complete_pipeline(df)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
